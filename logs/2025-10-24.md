# üóìÔ∏è Daily Log ‚Äì YYYY-MM-DD

**Focus:** Transformer Embedding categories for text similarity

## üß† What I Learned
- When it comes to calculating similarity between sentence or document pairs, there are two primary approaches: Bi-Encoder transformer models and Cross-Encoder transformer models.
- Bi-Encoders produce a vector representation for a given sentence or document chunk; which is usually a single vector of a fixed dimension.(Except for ColBert etc.)
- whether the input text is a single sentence, such as a user question, or a full paragraph, like a document excerpt, as long as the input fits within the embedding model's maximum sequence length, the output will be a fixed-dimension vector. 
- Overall Steps:
the pre-trained encoder model (usually BERT) converts the text into tokens, for each of which it has learned a vector representation during pre-training.\
It then applies a pooling step to average individual token representations into a single vector representation. 

- Key to improve RAG: chunking data into right size, choosing embedding model, chooing effetive retriveal mechanism.

- A larger context window lets you process bigger documents without losing information. This is helpful for tasks like searching long articles or research papers, or reports.

## üíª Snippet / Command
```py
from sentence_transformers import SentenceTransformer
sentences = ["This is an example sentence", "Each sentence is converted"]

model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
embeddings = model.encode(sentences)
print(embeddings)
outputs:
[[ 0.02250261 -0.0782918  -0.02303076 ... -0.00827925  0.02652694
  -0.00201898]
 [ 0.04170239  0.00109739 -0.01553419 ... -0.02181625 -0.06359357
  -0.00875283]]

```

‚ö†Ô∏è Speed-Bump / Question
- What is pooling step during converting token into embeddings?

üîó Links / References

- ‚≠ê https://unstructured.io/blog/understanding-embedding-models-make-an-informed-choice-for-your-rag
- https://levelup.gitconnected.com/how-to-choose-the-right-embedding-model-for-your-rag-application-44e30876d382
